{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b4df07-5b21-46d3-b64e-e5258d428757",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e89138-9df3-47b1-9550-668ff3a3d198",
   "metadata": {},
   "source": [
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bbaeda-975a-46c1-82af-78dfa00ba7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading dataset from HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "# For creating one-hot encodings of positive/negative instances\n",
    "import torch\n",
    "\n",
    "# Data saving\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da58fa86-0df7-4a5f-b145-91925cedb1a1",
   "metadata": {},
   "source": [
    "### Fixing Random Seeds for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3abe2b41-7432-4649-8fb4-40a3caa8e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e451b53-28d2-4680-88fd-6b8e2b16ad8d",
   "metadata": {},
   "source": [
    "### Making Project Folders to Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f791ec-9672-4085-a891-cbd598b599bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = \"./QLens/\" # Personalize if needed\n",
    "\n",
    "data_dir = proj_dir + \"Datasets/\"\n",
    "\n",
    "model_dir = proj_dir + \"Model_Checkpoints/\"\n",
    "lens_dir = proj_dir + \"Lens_Checkpoints/\"\n",
    "\n",
    "figures_dir = proj_dir + \"Figures/\"\n",
    "atten_figures_dir = proj_dir + \"Figures/Attention_Layer\"\n",
    "mlp_figures_dir = proj_dir + \"Figures/MLP_Layer\"\n",
    "\n",
    "os.makedirs(data_dir, exist_ok = True)\n",
    "os.makedirs(model_dir, exist_ok = True)\n",
    "os.makedirs(lens_dir, exist_ok = True)\n",
    "os.makedirs(atten_figures_dir, exist_ok = True)\n",
    "os.makedirs(mlp_figures_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83732003-0bcc-4158-9c3b-f2815309788d",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7e8356-534e-4d08-a88a-e7a32972e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Sentihood Dataset from HuggingFace\n",
    "ds = load_dataset(\"bhavnicksm/sentihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70fb7180-5231-4b01-94fd-c961c9e7884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Dataset Length: 1864\n",
      "Positive instances: 1329\n",
      "Negative instances: 535\n"
     ]
    }
   ],
   "source": [
    "ds = ds.shuffle(seed=42) # Shuffling dataset\n",
    "\n",
    "# Deriving input/output pairs for training a Transformer from the Sentihood dataset\n",
    "X = [] # Each instance will be a String of text whose sentiment is to be classified\n",
    "y = [] # Each instance will be a one-hot encoded torch Tensor describing positive or negative sentiment\n",
    "\n",
    "# Counters for positive and negative instances (used for balancing dataset to have an equal number of each)\n",
    "total_positive_instances = 0\n",
    "total_negative_instances = 0\n",
    "\n",
    "for split in list(dict(ds).keys()): # Looping through each dataset split\n",
    "  ds_split = ds[split]\n",
    "\n",
    "  for i in range(ds_split.num_rows):\n",
    "    target = ds_split[\"opinions\"][i]\n",
    "\n",
    "    if len(target) == 1: # Only instances with one target are retained to simplify task to single-intent prediction\n",
    "      X_instance = ds_split[\"text\"][i].strip()\n",
    "\n",
    "      if ds_split[\"opinions\"][i][0][\"sentiment\"] == \"Positive\":\n",
    "        y_instance = torch.Tensor([1, 0])\n",
    "        total_positive_instances += 1\n",
    "      else:\n",
    "        y_instance = torch.Tensor([0, 1])\n",
    "        total_negative_instances += 1\n",
    "\n",
    "      X.append(X_instance)\n",
    "      y.append(y_instance)\n",
    "\n",
    "print(\"Reduced Dataset Length:\", len(X))\n",
    "print(\"Positive instances:\", total_positive_instances)\n",
    "print(\"Negative instances:\", total_negative_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c9f482-dce1-4b34-ad76-5b9c6a8aa748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split size: 856\n",
      "Test split size: 214\n"
     ]
    }
   ],
   "source": [
    "# Creating balanced training and test input/output lists\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "train_test_ratio = 0.8 # 80:20 train/test split used\n",
    "\n",
    "positives = 0\n",
    "negatives = 0\n",
    "\n",
    "max_class_size = total_negative_instances if total_negative_instances < total_positive_instances else total_positive_instances\n",
    "cutoff = int(train_test_ratio * max_class_size)\n",
    "\n",
    "k = 0\n",
    "\n",
    "while len(X_train + X_test) < (2 * max_class_size): # Looping until all instances have been allocated to train or test set\n",
    "  if torch.equal(y[k], torch.tensor([1, 0]).float()): # Checking whether instance belongs to positive or negative class\n",
    "    positives += 1\n",
    "\n",
    "    if positives <= cutoff:\n",
    "      X_train.append(X[k])\n",
    "      y_train.append(y[k])\n",
    "    elif positives <= max_class_size:\n",
    "      X_test.append(X[k])\n",
    "      y_test.append(y[k])\n",
    "  else:\n",
    "    negatives += 1\n",
    "\n",
    "    if negatives <= cutoff:\n",
    "      X_train.append(X[k])\n",
    "      y_train.append(y[k])\n",
    "    elif negatives <= max_class_size:\n",
    "      X_test.append(X[k])\n",
    "      y_test.append(y[k])\n",
    "\n",
    "  k += 1\n",
    "\n",
    "print(\"Train split size:\", len(X_train))\n",
    "print(\"Test split size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "778a0907-bb22-4773-8517-98ff7973c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Train and Test splits\n",
    "\n",
    "train_dict = {'X': X_train, 'y': y_train}\n",
    "test_dict = {'X': X_test, 'y': y_test}\n",
    "\n",
    "train_path = data_dir + 'train.pickle'\n",
    "test_path = data_dir + 'test.pickle'\n",
    "\n",
    "with open(train_path, 'wb') as train_file:\n",
    "    pickle.dump(train_dict, train_file)\n",
    "\n",
    "with open(test_path, 'wb') as test_file:\n",
    "    pickle.dump(test_dict, test_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantum (conda)",
   "language": "python",
   "name": "quantum_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
